{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo: RAIL Evaluation \n",
    "\n",
    "Contact: _Julia Gschwend_ ([julia@linea.gov.br](mailto:julia@linea.gov.br)), _Sam Schmidt, Alex Malz, Eric Charles_\n",
    "\n",
    "\n",
    "The purpose of this notebook is to demonstrate the use of the metrics scripts to be used on the photo-z PDF catalogs produced by the PZ working group. The first implementation of the _evaluation_ module is based on the refactoring of the algorithms used in [Schmidt et al. 2020](https://arxiv.org/pdf/2001.03621.pdf), available on Github repository [PZDC1paper](https://github.com/LSSTDESC/PZDC1paper). \n",
    "\n",
    "\n",
    "To run this code, you must install qp and have the notebook in the same directory as metrics.py. You must also install some run-of-the-mill Python packages: numpy, scipy, matplotlib, and seaborn.\n",
    "\n",
    "### Contents\n",
    "\n",
    "* [Sample](#sample)\n",
    " - [Run FZBoost](#fzboost)\n",
    "* [CDF-based metrics](#cdf_metrics)\n",
    " - [PIT](#pit) \n",
    " - [QQ plot](#qq) \n",
    "* [Summary statistics of CDF-based metrics](#summary_stats)\n",
    "  - [KS](#ks) \n",
    "  - [CvM](#cvm) \n",
    "  - [AD](#ad) \n",
    "* [CDE loss](#cde_loss)  \n",
    "* [Summary](#summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from IPython.display import Markdown\n",
    "from sample import Sample\n",
    "from metrics import *\n",
    "import os\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"sample\"></a>\n",
    "\n",
    "# Sample  \n",
    "\n",
    "\n",
    "To compute the photo-z metrics of a given test sample, it is necessary to read the output of a photo-z code containing galaxies' photo-z PDFs. Let's use the toy data available in `tests/data/` (**test_dc2_training_9816.hdf5** and **test_dc2_validation_9816.hdf5**) and the configuration file available in `examples/configs/FZBoost.yaml` to generate a small samples of photo-z PDFs using the **FZBoost** algorithm available on RAIL's _estimation_ module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"fzboost\"></a>\n",
    "### Run FZBoost\n",
    "\n",
    "Go to dir  `<your_path>/RAIL/examples/` and run the command:\n",
    "\n",
    "`python main.py configs/FZBoost.yaml`\n",
    "\n",
    "The photo-z output files (inputs for this notebook) will be writen at: \n",
    "\n",
    "`<your_path>/RAIL/examples/results/FZBoost/test_FZBoost.hdf5`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_path = '/Users/julia/github/RAIL' # replace it by your path to RAIL's parent dir\n",
    "pdfs_file =  os.path.join(my_path, \"examples/results/FZBoost/test_FZBoost.hdf5\")\n",
    "ztrue_file =  os.path.join(my_path, \"tests/data/test_dc2_validation_9816.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a Sample object containing both the PDFs and true redshifts for each photo-z code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = Sample(pdfs_file, ztrue_file, code=\"FlexZBoost\", name=\"toy data\")\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PDFs of 5 galaxies for illustration. The function `plot_pdfs` calls a _qp_ built-in plot function and returns the color codes of galaxies whose indexes are include in the list `gals`. The galaxies in the example were chosen arbitrarily to cover the sample's redshift space. The dashed lines represent their respective true redshifts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gals = np.random.choice(len(ztrue), 5)\n",
    "gals = [540, 2256, 12175, 17802, 19502]\n",
    "colors = sample.plot_pdfs(gals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"cdf_metrics\"></a>\n",
    "# CDF-based metrics\n",
    "\n",
    "The folowing metrics are computed based on the photo-z PDFs. Let's create a Metrics object to access the basic metrics (e.g., PIT outlier rate, defined below) and basic plots. It is the parent class of other particular metrics. Instantiating a Metrics object can take a bit long depending on the sample's size because it preparates useful quantities to compute all metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "metrics = Metrics(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"pit\"></a>\n",
    "\n",
    "## PIT\n",
    "\n",
    "The first metric available is the Probability Integral Transform (PIT), which is the Cumulative Distribution Function (CDF) of the photo-z PDF \n",
    "\n",
    "$$ \\mathrm{CDF}(f, q)\\ =\\ \\int_{-\\infty}^{q}\\ f(z)\\ dz $$\n",
    "\n",
    "evaluated at the galaxy's true redshift for every galaxy $i$ in the catalog.\n",
    "\n",
    "$$ \\mathrm{PIT}(p_{i}(z);\\ z_{i})\\ =\\ \\int_{-\\infty}^{z^{true}_{i}}\\ p_{i}(z)\\ dz $$ \n",
    "\n",
    "For instance, the PIT values for the 5 PDFs shown above are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.pit[gals]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PIT outlier rate\n",
    "\n",
    "The PIT outlier rate is a global metric defined as the fraction of galaxies in the sample with extreme PIT values (PIT $<10^{-4}$ or PIT $>0.9999$). The lower and upper limits for considering a PIT as outlier are optional parameters set at the Metrics instantiation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pit_out_rate = PitOutRate(metrics).pit_out_rate\n",
    "print(f\"PIT outlier rate of this sample: {pit_out_rate:.4f}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When instantiating an individual metric object like `pit_out_rate` above, it updates the parent `metrics` object with the metric value. The same is valid for all infividual metrics shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.pit_out_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"qq\"></a>\n",
    "## PIT-QQ plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histogram of PIT values is a useful tool for a qualitative assessment of PDFs quality. It shows whether the PDFs are:\n",
    "* biased (tilted PIT histogram)\n",
    "* under-dispersed (excess counts close to the boudaries 0 and 1)\n",
    "* over-dispersed (lack of counts close the boudaries 0 and 1)\n",
    "* well-calibrated (flat histogram)\n",
    "\n",
    "Following the standards in DC1 paper, the PIT histogram is accompanied by the quantile-quantile (QQ), which can be used to compare qualitatively the PIT distribution obtained with the PDFs agaist the ideal case (uniform distribution). The closer the QQ plot is to the diagonal, the better is the PDFs calibration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.plot_pit_qq() #savefig=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the function `plot_pit_qq` displays both PIT histogram and the QQ plots together. The title and label are retrieved from sample's attributed for sample name and the photo-z (if not informed as optional parameters). It is also possible to select one plot at a time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.plot_pit_qq(show_pit=False, show_pit_out_rate=False, title=\"QQ only\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible ti set the number of bins in the PIT histigram. By default, it uses the same number of quantiles, which is an attribute of the metrics object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.n_quant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.plot_pit_qq(show_qq=False, title=\"PIT only\", bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The black horizontal line represents the ideal case where the PIT histogram would behave as a uniform distribution U(0,1). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore a different number of quantiles. By default, a Metrics object is instantiated with parameter `n_quant` = 100 percentiles. To redefine the number of quantiles, let's create a new Metrics object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_20 = Metrics(sample, n_quant=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_20.plot_pit_qq(title=\"N$_{quantiles}$=20\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"summary_stats\"></a>\n",
    "# Summary statistics of CDF-based metrics\n",
    "\n",
    "To evaluate globally the quality of PDFs estimates, `rail.evaluation` provides a set of metrics to compare the empirical distributions of PIT values with the reference uniform distribution, U(0,1). The individual metrics shown below are implemented as independent classes, in most cases receiving the metrics object as input, from where it can access the PIT array. These metrics can be accessed separately, or be called by one of the functions of the generic Metrics class (`markdown_metrics_table()` or `print_metrics_table()`), which calculate all metrics available at once. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"ks\"></a>\n",
    "### Kolmogorov-Smirnov  \n",
    "\n",
    "Let's start with the Kolmogorov-Smirnov (KS) statistic test, which is the maximum difference between the empirical and the expected cumulative distributions of PIT values:\n",
    "\n",
    "$$\n",
    "\\mathrm{KS} \\equiv \\max_{PIT} \\Big( \\left| \\ \\mathrm{CDF} \\small[ \\hat{f}, z \\small] - \\mathrm{CDF} \\small[ \\tilde{f}, z \\small] \\  \\right| \\Big)\n",
    "$$\n",
    "\n",
    "Where $\\hat{f}$ is the PIT distribution and $\\tilde{f}$ is U(0,1). Therefore, the smaller value of KS the closer the PIT distribution is to be uniform. The CDFs are calculated by qp.Ensamble CDF method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = KS(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks.stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks.pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visual interpretation of the KS statistic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"cvm\"></a>\n",
    "### Cramer-von Mises\n",
    "\n",
    "Similarly, let's calculate the Cramer-von Mises (CvM) test, a variant of the KS statistic defined as the mean-square difference between the CDFs of an empirical PDF and the true PDFs:\n",
    "\n",
    "$$ \\mathrm{CvM}^2 \\equiv \\int_{-\\infty}^{\\infty} \\Big( \\mathrm{CDF} \\small[ \\hat{f}, z \\small] \\ - \\ \\mathrm{CDF} \\small[ \\tilde{f}, z \\small] \\Big)^{2} \\mathrm{dCDF}(\\tilde{f}, z) $$ \n",
    "\n",
    "\n",
    "on the distribution of PIT values, which should be uniform if the PDFs are perfect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvm = CvM(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvm.stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvm.pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"ad\"></a>\n",
    "### Anderson-Darling \n",
    "\n",
    "Another variation of the KS statistic is the Anderson-Darling (AD) test, a weighted mean-squared difference featuring enhanced sensitivity to discrepancies in the tails of the distribution. \n",
    "\n",
    "$$ \\mathrm{AD}^2 \\equiv N_{tot} \\int_{-\\infty}^{\\infty} \\frac{\\big( \\mathrm{CDF} \\small[ \\hat{f}, z \\small] \\ - \\ \\mathrm{CDF} \\small[ \\tilde{f}, z \\small] \\big)^{2}}{\\mathrm{CDF} \\small[ \\tilde{f}, z \\small] \\big( 1 \\ - \\ \\mathrm{CDF} \\small[ \\tilde{f}, z \\small] \\big)}\\mathrm{dCDF}(\\tilde{f}, z) $$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad = AD(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad.stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to remove catastrophic outliers before calculating the integral for the sake of preserving numerical instability. For instance, Schmidt et al. computed the Anderson-Darling statistic within the interval (0.01,0.99)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_cut = AD(metrics, ad_pit_min=0.01, ad_pit_max=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_cut.stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"cde_loss\"></a>\n",
    "# CDE Loss\n",
    "\n",
    "\n",
    "\n",
    "In the absence of true photo-z posteriors, the metric used to evaluate individual PDFs is the **Conditional Density Estimate (CDE) Loss**, a metric analogue to the root-mean-squared-error:\n",
    "\n",
    "$$ L(f, \\hat{f}) \\equiv  \\int \\int {\\big(f(z | x) - \\hat{f}(z | x) \\big)}^{2} dzdP(x), $$ \n",
    "\n",
    "where $f(z | x)$ is the true photo-z PDF and $\\hat{f}(z | x)$ is the estimated PDF in terms of the photometry $x$. Since $f(z | x)$  is unknown, we estimate the **CDE Loss** as described in [Izbicki & Lee, 2017 (arXiv:1704.08095)](https://arxiv.org/abs/1704.08095). :\n",
    "\n",
    "$$ \\mathrm{CDE} = \\mathbb{E}\\big(  \\int{{\\hat{f}(z | X)}^2 dz} \\big) - 2{\\mathbb{E}}_{X, Z}\\big(\\hat{f}(Z, X) \\big) + K_{f},  $$\n",
    "\n",
    "\n",
    "where the first term is the expectation value of photo-z posterior with respect to the marginal distribution of the covariates X, and the second term is the expectation value  with respect to the joint distribution of observables X and the space Z of all possible redshifts (in practice, the centroids of the PDF bins), and the third term is a constant depending on the true conditional densities $f(z | x)$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cde_loss = CDE(metrics).cde_loss\n",
    "print(f\"CDE loss of this sample: {cde_loss:.2f}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"summary\"></a>\n",
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All metrics can be calculated at once and presented in a table by the main `metrics` object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.markdown_metrics_table()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
