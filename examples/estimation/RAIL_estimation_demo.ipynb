{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAIL/estimation Tutorial Notebook\n",
    "\n",
    "author: Sam Schmidt<br>\n",
    "last run successfully: April 29, 2021<br>\n",
    "\n",
    "This is a notebook demonstrating some of the features of the LSSTDESC `RAIL` package, namely the features of `estimation`.  `RAIL/estimation` is the interface for running production level photo-z codes within DESC.  There is a minimimal superclass that sets up some file paths and variable names, each specific photo-z code resides in a subclass with code-specific setup variables.<br>\n",
    "\n",
    "RAIL is available at:<br>\n",
    "https://github.com/LSSTDESC/RAIL<br>\n",
    "and must be installed and included in your python path to work.  The LSSTDESC `qp` package that handles PDF files is also required, it is available at:<br>\n",
    "https://github.com/LSSTDESC/qp<br>\n",
    "\n",
    "For convenience of running on cori @ NERSC, we have installed RAIL, qp, and all dependencies, the paths are included in cell #2 below.  So, if you are running at NERSC and using the `desc-python` kernel you should be able to run the notebook without any custom installations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import h5py\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,\"/global/cfs/cdirs/lsst/groups/PZ/users/sschmidt/Packages/RAIL\")\n",
    "sys.path.insert(0,\"/global/cfs/cdirs/lsst/groups/PZ/users/sschmidt/Packages/qp\")\n",
    "sys.path.insert(0,\"/global/cfs/cdirs/lsst/groups/PZ/users/sschmidt/Packages/tables_io\")\n",
    "sys.path.insert(0,\"/global/cfs/cdirs/lsst/groups/PZ/users/sschmidt/Packages/lib/python3.8/site-packages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rail\n",
    "from tables_io import io\n",
    "import qp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On importing RAIL you should see a list of the available photo-z algorithms, as printed out above.  These are the names of the specific subclasses that invoke a particular method, and they are stored in the `rail.estimation.algos` subdirectory of RAIL.<br>\n",
    "\n",
    "`randomPZ` is a very simple class that does not actually predict a meaningful photo-z, instead it produces a randomly drawn Gaussian for each galaxy.<br>\n",
    "`trainZ` is our \"pathological\" estimator, it makes a PDF from a histogram of the training data and assigns that PDF to every galaxy.<br>\n",
    "`simpleNN` uses `sklearn`'s neural network to predict a point redshift from the training data, then assigns a sigma width based on the redshift for another toy model example<br>\n",
    "`FZBoost` is a fully functional photo-z algorith, implementing the FlexZBoost conditional density estimate method that was used in the PhotoZDC1 paper.<br>\n",
    "\n",
    "## The `base_config` parameter file:\n",
    "\n",
    "RAIL/estimation is set up so that parameters for general setup (location of data and some settings) are stored in a local yaml file, while settings for a specific code can either be stored in a yaml file or a dictionary.<br>\n",
    "We will use the yaml file stored in the current directory called `example_estimation_base.yaml` which contains the following entries:<br>\n",
    "```\n",
    "base_config:\n",
    "  trainfile: ./Packages/RAIL/tests/data/test_dc2_training_9816.hdf5\n",
    "  testfile: ./Packages/RAIL/tests/data/test_dc2_validation_9816.hdf5\n",
    "  hdf5_groupname: photometry\n",
    "  chunk_size: 2500\n",
    "  configpath: ./configs\n",
    "  outpath: ./results\n",
    "  output_format: old\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This yaml file will be opened when a RAIL.estimation.Estimator class is invoked.  The quantities in the yaml file are:<br><br>\n",
    "-trainfile (str): path to the training data for this run<br>\n",
    "-testfile (str): path to the testing data for this run<br>\n",
    "-hdf5_groupname (str): the toplevel `groupname` for the hdf5 file, if the data is stored in the input hdf5 under e.g. `photometry`<br>\n",
    "-chunk_size (int): `tables_io` has an iterator method that can break the data in chunks of size `chunk_size` rather than run all at once<br>\n",
    "-configpath (str): location of config files<br>\n",
    "-outpath (str): directory in which to write output files<br>\n",
    "-output_format(str): If `output_format` is set to \"qp\" the method will return PDF data in qp format, if set to any other value it will return a dictionary.  We will demonstrate both data types in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The code-specific parameters\n",
    "Code-specific parameters are stored in a dictionary.  This dictionary should itself contain a dictionary named `run_params`.  If no second argument is supplied, the code will print a warning message and use a default set of values.<br>\n",
    "\n",
    "Let's start with a very simple demonstration using `simpleNN`.  `simpleNN` is just `sklearn`'s neural net method set up within the RAIL interface.  It estimates a point estimate redshift for each galaxy, then sets the width of the PDF based purely on the redshift.  This is a toy model estimator, but nicely illustrates some properties of RAIL. The parameters we'll use for simpleNN are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_dict = {'run_params': {\n",
    "  'class_name': 'simpleNN',\n",
    "  'run_name': 'test_simpleNN',\n",
    "  'zmin': 0.0,\n",
    "  'zmax': 3.0,\n",
    "  'nzbins': 301,\n",
    "  'width': 0.05,\n",
    "  'inform_options': {'save_train': True, 'load_model': False, 'modelfile': 'demo_NN_model.pkl'}\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In these parameters, `zmin`, `zmax`, and `nzbins` control the gridded parameterization on which the PDF will be output and stored (if not using `qp` format, in which case these parameters are ignored).<br>\n",
    "`width` sets the scale of the Gaussian width assumed for the PDFs.<br>\n",
    "`inform_options` is a dictionary that stores some information pertaining to the training process: <br>\n",
    "`modelfile` is a string argument that stores a filename.<br>    \n",
    "`save_train` is a boolean flag that if set to True will save the trained model to the filename stored in `modelfile` for later import.<br>\n",
    "`load_model` is a boolean flag that if set to true, will attempt to load a pretrained model from the filename in `modelfile`<br>\n",
    "\n",
    "We will see example uses of `save_train` and `load_model` later in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nn_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We instantiate a rail object with a call to the base class.<br>\n",
    "You can also find the specific class name from the name of the algorithm with:<br>\n",
    "```\n",
    "classname = 'simpleNN'\n",
    "code = Estimator._find_subclass(classname)\n",
    "```\n",
    "and then instantiate with \n",
    "```\n",
    "pz = code('example_estimation_base.yaml', nn_dict)  \n",
    "```\n",
    "We will hardcode here for the concrete example. The `simpleNN` class is in the file `rail/estimation/algos/sklearn_nn.py`, so to create an instance of this class we need a call to `rail.estimation.algos.sklearn_nn.simpleNN`.  Upon creation, the code will print a brief description of the parameters and their current values.  If any essential parameters are missing from the parameter dictionary, they will be set to default values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pz = rail.estimation.algos.sklearn_nn.simpleNN('example_estimation_base.yaml',nn_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's load our training data, which is stored in hdf5 format.  We'll load it with the `tables_io` function read, which returns a dictionary containing numpy arrays of all the columns in the hdf5 file, which matches the input format expected by the rail estimators.  Note that we specify the specific `pz.groupname` in brackets to load the particular hdf5 group that contains our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fmt = 'hdf5'\n",
    "training_data = io.read(pz.trainfile, None, train_fmt)[pz.groupname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(training_data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to train the neural net, which is done with the `inform` function present in every RAIL/estimation code. In `nn_dict` we have the `inform_options[save_train]` option set to `True`, so the trained model object will be saved in pickle format to the filename specified in `inform_options[modelfile]`, in this case `demo_NN_model.pkl`.  In the future, rather than re-run a potentially time consuming training set, we can simply load this pickle file.<br>\n",
    "\n",
    "NOTE: in our simple demo dataset, the multilevel perceptron sometimes fails to converge, so you may get a warning message in the next cell.  The estimator will still work and predict photo-z's even if the neural net was not quite converged in the set number of iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pz.inform(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now run our algorithm on the data to produce simple photo-z estimates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = io.read(pz.testfile, None, 'hdf5' )['photometry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = pz.estimate(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output file is a dictionary containing the redshift PDFs and the mode of the PDFs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the redshift mode against the true redshifts to see how they look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(test_data['redshift'],results_dict['zmode'],s=1,c='k',label='simple NN mode')\n",
    "plt.plot([0,3],[0,3],'r--');\n",
    "plt.xlabel(\"true redshift\")\n",
    "plt.ylabel(\"simple NN photo-z\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad, given our very simple estimator.  For the PDFs, the simpleNN is storing a gridded parameterization where the PDF is evaluated at a fixed set of redshifts for each galaxy.  That grid is stored in `pz.zgrid`, and we'll need that to plot.  Remember that our simple Neural Net just estimated a point photo-z then assumed a Gaussian, so all PDFs will be of that simple form.  Let's plot an example pdf:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "galid = 9529\n",
    "zgrid = pz.zgrid\n",
    "single_gal = results_dict['pz_pdf'][galid]\n",
    "single_zmode = results_dict['zmode'][galid]\n",
    "truez = test_data['redshift'][galid]\n",
    "plt.plot(zgrid,single_gal,color='k',label='single pdf')\n",
    "plt.axvline(single_zmode,color='k',label='mode')\n",
    "plt.axvline(truez,color='r',label='true redshift')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel(\"redshift\")\n",
    "plt.ylabel(\"p(z)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That illustrates the basics, now let's use a more well developed method, FZBoost, and use the iterator utility from `tables_io` to evaluate data in chunks, and output in `qp` format.  The `chunk_size` value in the base dictionary controls the number of galaxies used in each iterator chunk.<br>\n",
    "\n",
    "`FZBoost` finds a conditional density estimate for each PDF via a set of weights for basis functions.  This can save space relative to a gridded parameterization, but it also sometimes leads to residual \"bumps\" in the PDF from the underlying parameterization.  For this reason, `FZBoost` has a post-processing stage where it \"trims\" (i.e. sets to zero) any \"bumps\" below a certain threshold.<br>\n",
    "\n",
    "One of the dominant features seen in our PhotoZDC1 analysis of multiple photo-z codes (Schmidt et al. 2020) was that photo-z estimates were often, in general, overconfident or underconfident in their overall uncertainty in PDFs.  To remedy this, `FZBoost` has an additional post-processing step where it estimates a \"sharpening\" parameter that modulates the width of the PDFs.<br>\n",
    "\n",
    "A portion of the training data is held in reserve to find best-fit values for both `bump_thresh` and `sharpening`, which we find by simply calculating the CDE loss for a grid of `bump_thresh` and `sharpening` values.<br>\n",
    "\n",
    "We'll start with a dictionary of setup parameters for FZBoost, just as we had for simpleNN.  Some of the parameters are the same as in `simpleNN` above, `zmin`, `zmax`, `nzbins`.  However, FZBoost performs a more in depth training than simpleNN, and as such has more input parameters to control behavior.  These parameters are:<br>\n",
    "`basis_system`: which basis system to use in the density estimate. The default is `cosine` but `fourier` is also an option<br>\n",
    "`max_basis`: the maximum number of basis functions parameters to use for PDFs<br>\n",
    "`regression_params`: a dictionary of options fed to `xgboost` that control the maximum depth and the `objective` function.  An update in `xgboost` means that `objective` should now be set to `reg:squarederror` for proper functioning.<br>\n",
    "`trainfrac`: The fraction of the training data to use for training the density estimate.  The remaining galaxies will be used for validation of `bump_thresh` and `sharpening`.<br>\n",
    "`bumpmin`: the minimum value to test in the `bump_thresh` grid<br>\n",
    "`bumpmax`: the maximum value to test in the `bump_thresh` grid<br>\n",
    "`nbump`: how many points to test in the `bump_thresh` grid<br>\n",
    "`sharpmin`, `sharpmax`, `nsharp`: same as equivalent `bump_thresh` params, but for `sharpening` parameter<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fz_dict = {'run_params': {\n",
    "  'class_name': 'FZBoost',\n",
    "  'run_name': 'test_FZBoost',\n",
    "  'zmin': 0.0,\n",
    "  'zmax': 3.0,\n",
    "  'nzbins': 301,\n",
    "  'trainfrac': 0.75,\n",
    "  'bumpmin': 0.02,\n",
    "  'bumpmax': 0.35,\n",
    "  'nbump': 20,\n",
    "  'sharpmin': 0.7,\n",
    "  'sharpmax': 2.1,\n",
    "  'nsharp': 15,\n",
    "  'max_basis': 35,\n",
    "  'basis_system': 'cosine',\n",
    "  'regression_params': {'max_depth': 8,'objective':'reg:squarederror'},\n",
    "  'inform_options': {'save_train': True, 'load_model': False, 'modelfile': 'demo_FZB_model.pkl'}\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also demonstrate using qp as our storage format.  We will do this by using `example_estimation_base_qp.yaml`, which has the same parameters as `example_estimation_base.yaml`, but with `output_format` set to `qp` instead of `old`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pzflex = rail.estimation.algos.flexzboost.FZBoost('example_estimation_base_qp.yaml',fz_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use this data to train our model using `FZBoost`'s inform() method.  `FZBoost` uses xgboost to determine a conditional density estimate model, and also fits a `bump_thresh` parameter that erases small peaks that are an artifact of the `cosine` parameterization.  It then finds a best fit `sharpen` parameter that modulates the peaks with a power law.<br>\n",
    "We have `save_train` set to `True` in our `inform_options`, so this will save a pickled version of the best fit model to the file specified in `inform_options['modelfile']`, which is set above to `demo_FZB_model.pkl`.  We can use the same training data that we used for `simpleNN`.  `FZBoost` is a bit more sophisticated than `simpleNN`, so it will take a bit longer to train (note: it should take about 10-15 minutes on cori for the 10,000 galaxies in our demo sample):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pzflex.inform(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a pre-trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That took quite a while to train! But, because we had `inform_options[save_train]` set to `True` we have saved the pretrained model in the file `demo_FZB_model.pkl`.  To save time we can load this pickled model without having to repeat the training stage in future runs for this specific training data, and that should be much faster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pzflex.load_pretrained_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, under a second.  So, if you are running an algorithm with a burdensome training requirement, saving a trained copy of the model for later repeated use can be a real time saver."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add a temp qp append function!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's compute photo-z's using with the `estimate` method.  `tables_io` has a function that will iterate through the data returning dictionary of arrays as it goes named `iterHdf5ToDict`.  This can be useful if you have a very large datafile with millions of galaxies and you do not want to store all of the data in memory at once, and e.g. want to write out the PDFs to file as you progress.  Our demo file has only ~20,000 galaxies, but we will use the iterator here as an example.  the `tables_io` function `iterHdf5ToDict` takes arguments `infile` (path to the data file), `chunk_size` (how many galaxies you want to include in each iterator chunk), and `groupname` (the hdf5 groupname for the input data file).  We will use the same datafile used for our `simpleNN` demo.  Because we aren't writing to file, we will just stack the astropy tables returned by our iterator into one big qp file using the custom `qpappend` function defined in the cell above.  Again, if memory was a problem, you could instead write each file out to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "datafile =  \"Packages/RAIL/tests/data/test_dc2_validation_9816.hdf5\"\n",
    "for chunk, (start, end, data) in enumerate(io.iterHdf5ToDict(pz.testfile, pz._chunk_size, 'photometry')):\n",
    "    print(f\"calculating pdfs[{start}:{end}]\")\n",
    "    pz_data_chunk = pzflex.estimate(data)\n",
    "    if chunk == 0:\n",
    "        FZ_pdfs = pz_data_chunk\n",
    "    else:\n",
    "        FZ_pdfs.append(pz_data_chunk)\n",
    "        del pz_data_chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot an example PDF using `qp`'s native plotting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = qp.plotting.plot_native(FZ_pdfs[1225], xlim=(0.,3.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot a few point estimates to make sure our algorithm worked properly, we can compute the median of the PDF trivially and plot against true redshift:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fz_medians = FZ_pdfs.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(test_data['redshift'],Fz_medians,s=1,c='k')\n",
    "plt.plot([0,3],[0,3],'r--')\n",
    "plt.xlabel(\"true redshift\")\n",
    "plt.ylabel(\"photoz median\")\n",
    "plt.title(\"median point estimate for FZBoost\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, the `qp.interp` parameterization used for `FZBoost` doest not have a native `mode()` method, but we can easily compute the mode using `np.argmax` on each PDF and assigning the `pz.zgrid` value.  Note that this works only for this particular `qp` paremeterization, and would be different for alternate storage forms.  for `qp.interp` the raw gridded PDFs are stored in `objdata()['yvals']`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawfzdata = FZ_pdfs.objdata()['yvals']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FZ_mode = pzflex.zgrid[np.argmax(rawfzdata,axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(test_data['redshift'],FZ_mode,c='k',s=1)\n",
    "plt.plot([0,3],[0,3],'r--')\n",
    "plt.xlabel(\"true redshift\")\n",
    "plt.ylabel(\"photoz mode\")\n",
    "plt.title(\"PDF mode for FZBoost\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results look very good! FZBoost is a mature algorithm, and with representative training data we see a very tight correlation with true redshift and few outliers.<br>\n",
    "\n",
    "We can use this same raw data to see how the summed PDFs compare to the true redshift distribution (note: this is as a sanity check rather than a \"proper\" analysis for science, for which we might want to use something like chippr to properly estimate the overall probability distribution):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FZ_nzsum = np.sum(rawfzdata,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(pz.zgrid,FZ_nzsum*.03, label='summed PDFs')\n",
    "plt.hist(test_data['redshift'],bins=np.linspace(0.,3.,101), label=\"true z histogram\");\n",
    "plt.xlabel(\"redshift\")\n",
    "plt.ylabel(\"N(z)\")\n",
    "plt.legend(loc='upper right');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
