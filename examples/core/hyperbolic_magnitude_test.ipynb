{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "202fb6c0-df9a-42cf-9b78-ff93496ee884",
   "metadata": {},
   "source": [
    "# Computing hyperbolic magnitudes\n",
    "\n",
    "[Implementation](https://github.com/jlvdb/hyperbolic) of Luption et al. (1999) by Jan Luca van den Busch.\n",
    "\n",
    "Hyperbolic magnitudes aim to overcome limitations of classical magnitudes, which are logarithmic in flux. Hyperbolic magnitudues are implemented using the inverse hyperbolic sine and therefore have a linear behaviour in flux at low signal to noise, which gradually transitions to the classical logarithmic scaling at high signal to noise (i.e. equivalent to classical magnitudes in this limit).\n",
    "\n",
    "This notebooks provides an example of how to convert classical to hyperbolical magnitudes using the pipeline stages `HyperbolicSmoothing` and `HyperbolicMagnitudes`in the `rail.core` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf487635-aea8-4b65-8606-cf0d438e0e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import hyperbolic\n",
    "\n",
    "import rail\n",
    "from rail.core.data import TableHandle\n",
    "from rail.core.stage import RailStage\n",
    "from rail.core.utilPhotometry import HyperbolicSmoothing, HyperbolicMagnitudes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ff5986-1a7f-4de4-99f9-31f2c3361c7d",
   "metadata": {},
   "source": [
    "We first set up a data store for interactive usage of RAIL (see the `rail/examples/goldenspike/goldenspike.ipynb` for further examples)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737027fd-bc20-4450-aabb-d5f2d69577bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "DS = RailStage.data_store\n",
    "DS.__class__.allow_overwrite = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30314afd-3643-47aa-80f5-7280e9f610bb",
   "metadata": {},
   "source": [
    "Next we load some DC2 sample data that provides LSST ugrizy magnitudes and magnitude errors, which we want to convert to hyperbolic magnitudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15ae47d-5e50-410a-890c-caf30763d1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAIL_DIR = os.path.dirname(rail.__file__)\n",
    "testFile = os.path.join(RAIL_DIR, '../tests/data/test_dc2_training_9816.pq')\n",
    "test_mags = DS.read_file(\"test_data\", TableHandle, testFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc93c6ca-9c8f-4b1f-9d25-362606756a71",
   "metadata": {},
   "source": [
    "## Determining the smoothing parameters\n",
    "\n",
    "First we run the `rail.core.HyperbolicSmoothing` stage. This stage computes the smoothing parameter (called $b$ in Lupton et al. 1999), which determines the transition between the linear and logarithmic behaviour of the hyperbolic magnitudes.\n",
    "\n",
    "The **input** for this stage is a table containing magnitudes and magnitude errors per object. In this example, we assume that the magnitude zeropoint is 0.0 and that we want to convert all 6 LSST bands. This can be specified with the `magnitude_columns` and `magerror_columns` parameters, which list the names of the magnitude columns and their corresponding magnitude errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7e83a1-c1b3-43ff-996f-be8e788f3061",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsst_bands = 'ugrizy'\n",
    "coldefs = dict(\n",
    "    magnitude_columns=[f\"mag_{band}_lsst\" for band in lsst_bands],\n",
    "    magerror_columns=[f\"mag_err_{band}_lsst\" for band in lsst_bands])\n",
    "\n",
    "smooth = HyperbolicSmoothing.make_stage(\n",
    "    name='hyperbolic_smoothing',\n",
    "    zeropoint=0.0, **coldefs)\n",
    "smooth.compute(test_mags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708f159c-7db7-4212-a4b2-f74f3fe7241e",
   "metadata": {},
   "source": [
    "The **output** of this stage is a table of relevant statistics required to compute the hyperbolic magnitudes per filter:\n",
    "- the median flux error\n",
    "- the zeropoint (which can be computed by comparing fluxes and magnitudes in the original `hyperbolic` code)\n",
    "- the reference flux $f_{\\rm ref}$ that corresponds to the given zeropoint\n",
    "- the smoothing parameter $b$ (in terms of the absolute and the relative flux $x = f / f_{\\rm ref}$\n",
    "\n",
    "The `field ID` column is currently not used by the RAIL module and can be ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085e904e-a615-4f18-b0c2-4e1c555ff009",
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth_params = smooth.get_handle(\"parameters\").data\n",
    "smooth_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf17139-4ac6-4cf2-adda-9850d8967a52",
   "metadata": {},
   "source": [
    "## Computing the magnitudes\n",
    "\n",
    "Based on the smoothing parameters, the hyperbolic magnitudes are computed with be computed by `rail.core.HyperbolicMagnitudes`.\n",
    "\n",
    "The **input** for this module is, again, the table with magnitudes and magnitude errors and the output table of `rail.core.HyperbolicSmoothing`, as well as the column names as defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce901bb-82ff-4601-8136-53b394b17de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypmag = HyperbolicMagnitudes.make_stage(\n",
    "    name='hyperbolic_magnitudes',\n",
    "    **coldefs)\n",
    "hypmag.compute(test_mags, smooth_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1dd56a-859e-4352-a34a-afc520a72694",
   "metadata": {},
   "source": [
    "The **output** of this module is a table with hyperbolic magnitudes and their corresponding error.\n",
    "\n",
    "**Note:** The current default is to relabel the columns names by substituting `mag_` by `mag_hyp_`. If this substitution is not possible, the column names are identical to the input table with classical magnitudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dca1a7a-3ea7-40fd-b0ad-ce75dbc7848b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_hypmags = hypmag.get_handle(\"output\").data\n",
    "test_hypmags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1fff3e-723f-4667-bff4-d66c93ba9b9c",
   "metadata": {},
   "source": [
    "## Some check plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9824e8e0-3e73-4017-8447-783ce5032011",
   "metadata": {},
   "outputs": [],
   "source": [
    "filt = \"r\"\n",
    "\n",
    "mag_class = test_mags.data[f\"mag_{filt}_lsst\"]\n",
    "magerr_class = test_mags.data[f\"mag_err_{filt}_lsst\"]\n",
    "mag_hyp = test_hypmags[f\"mag_hyp_{filt}_lsst\"]\n",
    "magerr_hyp = test_hypmags[f\"mag_hyp_err_{filt}_lsst\"]\n",
    "# flux_class = np.exp((0.0 - mag_class) / hyperbolic.pogson)\n",
    "# fluxerr_class = magerr_class / hyperbolic.pogson * flux_class\n",
    "# SN = flux_class / fluxerr_class\n",
    "\n",
    "fig = plt.figure(dpi=100)\n",
    "plt.axhline(y=0.0, color=\"k\", lw=0.55)\n",
    "plt.scatter(mag_class, mag_class - mag_hyp, s=1)\n",
    "plt.xlabel(\"Classical magnitudue\")\n",
    "plt.ylabel(\"Classical $-$ hyperbolic magnitude\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fcd087-00eb-4b41-a3f6-de54ed4b8759",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
