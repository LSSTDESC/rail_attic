{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo: RAIL Evaluation \n",
    "\n",
    "Author: Sam Schmidt, Alex Malz, Julia Gschwend, others...\n",
    "\n",
    "last run successfully: March 16, 2022\n",
    "\n",
    "The purpose of this notebook is to demonstrate the application of the metrics scripts to be used on the photo-z PDF catalogs produced by the PZ working group. The first implementation of the _evaluation_ module is based on the refactoring of the code used in [Schmidt et al. 2020](https://arxiv.org/pdf/2001.03621.pdf), available on Github repository [PZDC1paper](https://github.com/LSSTDESC/PZDC1paper). \n",
    "\n",
    "To run this notebook, you must install qp and have the notebook in the same directory as `utils.py` (available in RAIL's examples directrory). You must also have installed all RAIL dependencies, particularly for the estimation codes that you want to run, as well as ceci, qp, tables_io, etc...  See the RAIL installation instructions for more info.\n",
    "\n",
    "### Contents\n",
    "\n",
    "* [Data](#data)\n",
    " - [Photo-z Results](#fzboost)\n",
    "* [CDF-based metrics](#metrics)\n",
    " - [PIT](#pit) \n",
    " - [QQ plot](#qq) \n",
    "* [Summary statistics of CDF-based metrics](#summary_stats)\n",
    "  - [KS](#ks) \n",
    "  - [CvM](#cvm) \n",
    "  - [AD](#ad) \n",
    "  - [KLD](#kld) \n",
    "* [CDE loss](#cde_loss)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rail\n",
    "from rail.evaluation.metrics.pit import *\n",
    "from rail.evaluation.metrics.cdeloss import *\n",
    "from rail.evaluation.evaluator import Evaluator\n",
    "from rail.core.data import QPHandle, TableHandle\n",
    "from rail.core.stage import RailStage\n",
    "#from utils import plot_pit_qq, ks_plot\n",
    "import qp \n",
    "import os\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set up the data store, for more information on the data store, see the golden spike example notebook in RAIL/examples/goldenspike/goldenspike.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS = RailStage.data_store\n",
    "DS.__class__.allow_overwrite = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"data\"></a>\n",
    "# Data  \n",
    "\n",
    "\n",
    "To compute the photo-z metrics of a given test sample, it is necessary to read the output of a photo-z code containing galaxies' photo-z PDFs. Let's use the toy data available in `tests/data/` (**test_dc2_training_9816.hdf5** and **test_dc2_validation_9816.hdf5**) to generate a small sample of photo-z PDFs using the **FZBoost** algorithm available on RAIL's _estimation_ module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"fzboost\"></a>\n",
    "### Photo-z Results\n",
    "#### Run FZBoost\n",
    "\n",
    "Go to dir  `<your_path>/RAIL/examples/estimation/` (i.e. \"../estimation\" relative to the directory you are running this notebook) and run the notebook `RAIL_estimation_demo.ipynb`, this will produce a file `output_fzboost.fits`\n",
    "\n",
    "writen at the location:<br> \n",
    "`<your_path>/RAIL/examples/estimation/output_fzboost.fits`. \n",
    "This will run FZBoost and write out the PDF results as a qp Ensemble that we will then use in this example notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to set up some  paths for the Data Store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rail.core.utils import RAILDIR\n",
    "pdfs_file = \"../estimation/output_fzboost.hdf5\"\n",
    "ztrue_file = os.path.join(RAILDIR, 'rail/examples/testdata/test_dc2_validation_9816.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the data in, note that the fzdata is a `qp` Ensemble, and thus we should read it in as a `QPHandle` type file, while the ztrue_data is tabular data, and should be read in as a `Tablehandle` when adding to the data store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to open file (unable to open file: name = '../estimation/output_fzboost.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m fzdata \u001b[38;5;241m=\u001b[39m DS\u001b[38;5;241m.\u001b[39mread_file(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpdfs_data\u001b[39m\u001b[38;5;124m'\u001b[39m, QPHandle, pdfs_file)\n\u001b[1;32m      2\u001b[0m ztrue_data \u001b[38;5;241m=\u001b[39m DS\u001b[38;5;241m.\u001b[39mread_file(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mztrue_data\u001b[39m\u001b[38;5;124m'\u001b[39m, TableHandle, ztrue_file)\n",
      "File \u001b[0;32m~/software/DESC/DESCFormats/src/descformats/data.py:76\u001b[0m, in \u001b[0;36mDataStore.read_file\u001b[0;34m(self, key, handle_class, path, creator, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;124;03m\"\"\" Create a handle, use it to read a file, and insert it into the DataStore \"\"\"\u001b[39;00m\n\u001b[1;32m     75\u001b[0m handle \u001b[38;5;241m=\u001b[39m handle_class(key, path\u001b[38;5;241m=\u001b[39mpath, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, creator\u001b[38;5;241m=\u001b[39mcreator)\n\u001b[0;32m---> 76\u001b[0m \u001b[43mhandle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28mself\u001b[39m[key] \u001b[38;5;241m=\u001b[39m handle\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m handle\n",
      "File \u001b[0;32m~/software/DESC/DESCFormats/src/descformats/handle.py:73\u001b[0m, in \u001b[0;36mDataHandle.read\u001b[0;34m(self, force, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m force:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\n\u001b[0;32m---> 73\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_data(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\n",
      "File \u001b[0;32m~/software/DESC/RAIL/src/rail/core/data.py:47\u001b[0m, in \u001b[0;36mQPHandle._read\u001b[0;34m(cls, path, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read\u001b[39m(\u001b[38;5;28mcls\u001b[39m, path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;124;03m\"\"\"Read and return the data from the associated file \"\"\"\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mqp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rail-py39/lib/python3.9/site-packages/qp_prob-0.6.3-py3.9.egg/qp/factory.py:146\u001b[0m, in \u001b[0;36mFactory.read\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m    143\u001b[0m     keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    144\u001b[0m     allow_missing_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 146\u001b[0m tables \u001b[38;5;241m=\u001b[39m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNUMPY_DICT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mallow_missing_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_missing_keys\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#pylint: disable=no-member\u001b[39;00m\n\u001b[1;32m    149\u001b[0m md_table \u001b[38;5;241m=\u001b[39m tables[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmeta\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    150\u001b[0m data_table \u001b[38;5;241m=\u001b[39m tables[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/rail-py39/lib/python3.9/site-packages/tables_io-0.7.9-py3.9.egg/tables_io/ioUtils.py:946\u001b[0m, in \u001b[0;36mread\u001b[0;34m(filepath, tType, fmt, keys, allow_missing_keys)\u001b[0m\n\u001b[1;32m    924\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(filepath, tType\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, fmt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allow_missing_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    925\u001b[0m     \u001b[38;5;124;03m\"\"\" Read a file to the corresponding table type\u001b[39;00m\n\u001b[1;32m    926\u001b[0m \n\u001b[1;32m    927\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m \n\u001b[1;32m    945\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 946\u001b[0m     odict \u001b[38;5;241m=\u001b[39m \u001b[43mreadNative\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_missing_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(odict) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    948\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m defName \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__astropy_table__\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "File \u001b[0;32m~/miniconda3/envs/rail-py39/lib/python3.9/site-packages/tables_io-0.7.9-py3.9.egg/tables_io/ioUtils.py:913\u001b[0m, in \u001b[0;36mreadNative\u001b[0;34m(filepath, fmt, keys, allow_missing_keys)\u001b[0m\n\u001b[1;32m    911\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m readHdf5ToApTables(filepath)\n\u001b[1;32m    912\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fType \u001b[38;5;241m==\u001b[39m NUMPY_HDF5:\n\u001b[0;32m--> 913\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mreadHdf5ToDicts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fType \u001b[38;5;241m==\u001b[39m NUMPY_FITS:\n\u001b[1;32m    915\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m readFitsToRecarrays(filepath)\n",
      "File \u001b[0;32m~/miniconda3/envs/rail-py39/lib/python3.9/site-packages/tables_io-0.7.9-py3.9.egg/tables_io/ioUtils.py:651\u001b[0m, in \u001b[0;36mreadHdf5ToDicts\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreadHdf5ToDicts\u001b[39m(filepath):\n\u001b[1;32m    638\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;124;03m    Reads `numpy.array` objects from an hdf5 file.\u001b[39;00m\n\u001b[1;32m    640\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[38;5;124;03m        The data\u001b[39;00m\n\u001b[1;32m    650\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 651\u001b[0m     fin \u001b[38;5;241m=\u001b[39m \u001b[43mh5py\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    652\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m OrderedDict([(key, readHdf5GroupToDict(val)) \u001b[38;5;28;01mfor\u001b[39;00m key, val \u001b[38;5;129;01min\u001b[39;00m fin\u001b[38;5;241m.\u001b[39mitems()])\n",
      "File \u001b[0;32m~/miniconda3/envs/rail-py39/lib/python3.9/site-packages/h5py/_hl/files.py:533\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, **kwds)\u001b[0m\n\u001b[1;32m    525\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[1;32m    526\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[1;32m    527\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[1;32m    528\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[1;32m    529\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    530\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[1;32m    531\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[1;32m    532\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[0;32m--> 533\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[0;32m~/miniconda3/envs/rail-py39/lib/python3.9/site-packages/h5py/_hl/files.py:226\u001b[0m, in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[1;32m    225\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[0;32m--> 226\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    228\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5f.pyx:106\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to open file (unable to open file: name = '../estimation/output_fzboost.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "fzdata = DS.read_file('pdfs_data', QPHandle, pdfs_file)\n",
    "ztrue_data = DS.read_file('ztrue_data', TableHandle, ztrue_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ztrue = ztrue_data()['photometry']['redshift']\n",
    "zgrid = fzdata().metadata()['xvals'].ravel()\n",
    "photoz_mode = fzdata().mode(grid=zgrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ztrue_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m truth \u001b[38;5;241m=\u001b[39m DS\u001b[38;5;241m.\u001b[39madd_data(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtruth\u001b[39m\u001b[38;5;124m'\u001b[39m, ztrue_data()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mphotometry\u001b[39m\u001b[38;5;124m'\u001b[39m], TableHandle)\n\u001b[1;32m      2\u001b[0m ensemble \u001b[38;5;241m=\u001b[39m DS\u001b[38;5;241m.\u001b[39madd_data(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mensemble\u001b[39m\u001b[38;5;124m'\u001b[39m, fzdata, QPHandle)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ztrue_data' is not defined"
     ]
    }
   ],
   "source": [
    "truth = DS.add_data('truth', ztrue_data()['photometry'], TableHandle)\n",
    "ensemble = DS.add_data('ensemble', fzdata, QPHandle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make an evaulator stage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's set up the Evaluator stage to compute our metrics for the FZBoost data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FZB_eval = Evaluator.make_stage(name='FZB_eval', truth=truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FZB_results = FZB_eval.evaluate(ensemble(), truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can view the results as a pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tables_io\n",
    "results_df= tables_io.convertObj(FZB_results(), tables_io.types.PD_DATAFRAME)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, there we have it, a way to generate all of our summary statistics for FZBoost. And note also that the results file has been written out to `output_FZB_eval.hdf5`, the name we specified when we ran `make_stage` (with output_ prepended).<br>\n",
    "\n",
    "As an alternative, and to allow for a little more explanation for each individual metric, we can calculate the metrics using functions from the evaluation class separate from the stage infrastructure.  Here are some examples below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** \n",
    "<a class=\"anchor\" id=\"metrics\"></a>\n",
    "# Metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"pit\"></a>\n",
    "## PIT\n",
    "\n",
    "The Probability Integral Transform (PIT), is the Cumulative Distribution Function (CDF) of the photo-z PDF \n",
    "\n",
    "$$ \\mathrm{CDF}(f, q)\\ =\\ \\int_{-\\infty}^{q}\\ f(z)\\ dz $$\n",
    "\n",
    "evaluated at the galaxy's true redshift for every galaxy $i$ in the catalog.\n",
    "\n",
    "$$ \\mathrm{PIT}(p_{i}(z);\\ z_{i})\\ =\\ \\int_{-\\infty}^{z^{true}_{i}}\\ p_{i}(z)\\ dz $$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitobj = PIT(fzdata(), ztrue)\n",
    "quant_ens, metamets = pitobj.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The _evaluate_ method PIT class returns two objects, a quantile distribution based on the full set of PIT values (a frozen distribution object), and a dictionary of meta metrics associated to PIT (to be detailed below). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_ens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metamets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PIT values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pit_vals = np.array(pitobj._pit_samps)\n",
    "pit_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PIT outlier rate\n",
    "\n",
    "The PIT outlier rate is a global metric defined as the fraction of galaxies in the sample with extreme PIT values. The lower and upper limits for considering a PIT as outlier are optional parameters set at the Metrics instantiation (default values are: PIT $<10^{-4}$ or PIT $>0.9999$). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pit_out_rate = PITOutRate(pit_vals, quant_ens).evaluate()\n",
    "print(f\"PIT outlier rate of this sample: {pit_out_rate:.6f}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"qq\"></a>\n",
    "## PIT-QQ plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histogram of PIT values is a useful tool for a qualitative assessment of PDFs quality. It shows whether the PDFs are:\n",
    "* biased (tilted PIT histogram)\n",
    "* under-dispersed (excess counts close to the boudaries 0 and 1)\n",
    "* over-dispersed (lack of counts close the boudaries 0 and 1)\n",
    "* well-calibrated (flat histogram)\n",
    "\n",
    "Following the standards in DC1 paper, the PIT histogram is accompanied by the quantile-quantile (QQ), which can be used to compare qualitatively the PIT distribution obtained with the PDFs agaist the ideal case (uniform distribution). The closer the QQ plot is to the diagonal, the better is the PDFs calibration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfs = fzdata.data.objdata()['yvals']\n",
    "plot_pit_qq(pdfs, zgrid, ztrue, title=\"PIT-QQ - toy data\", code=\"FZBoost\",\n",
    "                pit_out_rate=pit_out_rate, savefig=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The black horizontal line represents the ideal case where the PIT histogram would behave as a uniform distribution U(0,1). \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"summary_stats\"></a>\n",
    "# Summary statistics of CDF-based metrics\n",
    "\n",
    "To evaluate globally the quality of PDFs estimates, `rail.evaluation` provides a set of metrics to compare the empirical distributions of PIT values with the reference uniform distribution, U(0,1). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"ks\"></a>\n",
    "### Kolmogorov-Smirnov  \n",
    "\n",
    "Let's start with the traditional Kolmogorov-Smirnov (KS) statistic test, which is the maximum difference between the empirical and the expected cumulative distributions of PIT values:\n",
    "\n",
    "$$\n",
    "\\mathrm{KS} \\equiv \\max_{PIT} \\Big( \\left| \\ \\mathrm{CDF} \\small[ \\hat{f}, z \\small] - \\mathrm{CDF} \\small[ \\tilde{f}, z \\small] \\  \\right| \\Big)\n",
    "$$\n",
    "\n",
    "Where $\\hat{f}$ is the PIT distribution and $\\tilde{f}$ is U(0,1). Therefore, the smaller value of KS the closer the PIT distribution is to be uniform. The `evaluate` method of the PITKS class returns a named tuple with the statistic and p-value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ksobj = PITKS(pit_vals, quant_ens)\n",
    "ks_stat_and_pval = ksobj.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_stat_and_pval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visual interpretation of the KS statistic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_plot(pitobj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"KS metric of this sample: {ks_stat_and_pval.statistic:.4f}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"cvm\"></a>\n",
    "### Cramer-von Mises\n",
    "\n",
    "Similarly, let's calculate the Cramer-von Mises (CvM) test, a variant of the KS statistic defined as the mean-square difference between the CDFs of an empirical PDF and the true PDFs:\n",
    "\n",
    "$$ \\mathrm{CvM}^2 \\equiv \\int_{-\\infty}^{\\infty} \\Big( \\mathrm{CDF} \\small[ \\hat{f}, z \\small] \\ - \\ \\mathrm{CDF} \\small[ \\tilde{f}, z \\small] \\Big)^{2} \\mathrm{dCDF}(\\tilde{f}, z) $$ \n",
    "\n",
    "\n",
    "on the distribution of PIT values, which should be uniform if the PDFs are perfect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvmobj = PITCvM(pit_vals, quant_ens)\n",
    "cvm_stat_and_pval = cvmobj.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"CvM metric of this sample: {cvm_stat_and_pval.statistic:.4f}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"ad\"></a>\n",
    "### Anderson-Darling \n",
    "\n",
    "Another variation of the KS statistic is the Anderson-Darling (AD) test, a weighted mean-squared difference featuring enhanced sensitivity to discrepancies in the tails of the distribution. \n",
    "\n",
    "$$ \\mathrm{AD}^2 \\equiv N_{tot} \\int_{-\\infty}^{\\infty} \\frac{\\big( \\mathrm{CDF} \\small[ \\hat{f}, z \\small] \\ - \\ \\mathrm{CDF} \\small[ \\tilde{f}, z \\small] \\big)^{2}}{\\mathrm{CDF} \\small[ \\tilde{f}, z \\small] \\big( 1 \\ - \\ \\mathrm{CDF} \\small[ \\tilde{f}, z \\small] \\big)}\\mathrm{dCDF}(\\tilde{f}, z) $$ \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adobj = PITAD(pit_vals, quant_ens)\n",
    "ad_stat_crit_sig = adobj.evaluate()\n",
    "ad_stat_crit_sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_stat_crit_sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"AD metric of this sample: {ad_stat_crit_sig.statistic:.4f}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to remove catastrophic outliers before calculating the integral for the sake of preserving numerical instability. For instance, Schmidt et al. computed the Anderson-Darling statistic within the interval (0.01, 0.99)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_stat_crit_sig_cut = adobj.evaluate(pit_min=0.01, pit_max=0.99)\n",
    "print(f\"AD metric of this sample: {ad_stat_crit_sig.statistic:.4f}\") \n",
    "print(f\"AD metric for 0.01 < PIT < 0.99: {ad_stat_crit_sig_cut.statistic:.4f}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"cde_loss\"></a>\n",
    "# CDE Loss\n",
    "\n",
    "\n",
    "\n",
    "In the absence of true photo-z posteriors, the metric used to evaluate individual PDFs is the **Conditional Density Estimate (CDE) Loss**, a metric analogue to the root-mean-squared-error:\n",
    "\n",
    "$$ L(f, \\hat{f}) \\equiv  \\int \\int {\\big(f(z | x) - \\hat{f}(z | x) \\big)}^{2} dzdP(x), $$ \n",
    "\n",
    "where $f(z | x)$ is the true photo-z PDF and $\\hat{f}(z | x)$ is the estimated PDF in terms of the photometry $x$. Since $f(z | x)$  is unknown, we estimate the **CDE Loss** as described in [Izbicki & Lee, 2017 (arXiv:1704.08095)](https://arxiv.org/abs/1704.08095). :\n",
    "\n",
    "$$ \\mathrm{CDE} = \\mathbb{E}\\big(  \\int{{\\hat{f}(z | X)}^2 dz} \\big) - 2{\\mathbb{E}}_{X, Z}\\big(\\hat{f}(Z, X) \\big) + K_{f},  $$\n",
    "\n",
    "\n",
    "where the first term is the expectation value of photo-z posterior with respect to the marginal distribution of the covariates X, and the second term is the expectation value  with respect to the joint distribution of observables X and the space Z of all possible redshifts (in practice, the centroids of the PDF bins), and the third term is a constant depending on the true conditional densities $f(z | x)$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdelossobj = CDELoss(fzdata.data, zgrid, ztrue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cde_stat_and_pval = cdelossobj.evaluate()\n",
    "cde_stat_and_pval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"CDE loss of this sample: {cde_stat_and_pval.statistic:.2f}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that all of the quantities as run individually are identical to the quantities in our summary table, a nice check that things have run properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
