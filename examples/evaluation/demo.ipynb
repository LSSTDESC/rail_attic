{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo: RAIL Evaluation \n",
    "\n",
    "The purpose of this notebook is to demonstrate the application of the metrics scripts to be used on the photo-z PDF catalogs produced by the PZ working group. The first implementation of the _evaluation_ module is based on the refactoring of the code used in [Schmidt et al. 2020](https://arxiv.org/pdf/2001.03621.pdf), available on Github repository [PZDC1paper](https://github.com/LSSTDESC/PZDC1paper). \n",
    "\n",
    "To run this notebook, you must install qp and have the notebook in the same directory as `utils.py` (available in RAIL's examples directrory). You must also install some run-of-the-mill Python packages: numpy, scipy, matplotlib, and seaborn.\n",
    "\n",
    "### Contents\n",
    "\n",
    "* [Data](#data)\n",
    " - [Photo-z Results](#fzboost)\n",
    "* [CDF-based metrics](#metrics)\n",
    " - [PIT](#pit) \n",
    " - [QQ plot](#qq) \n",
    "* [Summary statistics of CDF-based metrics](#summary_stats)\n",
    "  - [KS](#ks) \n",
    "  - [CvM](#cvm) \n",
    "  - [AD](#ad) \n",
    "  - [KLD](#kld) \n",
    "* [CDE loss](#cde_loss)  \n",
    "* [Summary](#summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rail.evaluation.metrics.pit import *\n",
    "from rail.evaluation.metrics.cdeloss import *\n",
    "from utils import read_pz_output, plot_pit_qq, ks_plot\n",
    "from main import Summary\n",
    "import qp \n",
    "import os\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"data\"></a>\n",
    "# Data  \n",
    "\n",
    "\n",
    "To compute the photo-z metrics of a given test sample, it is necessary to read the output of a photo-z code containing galaxies' photo-z PDFs. Let's use the toy data available in `tests/data/` (**test_dc2_training_9816.hdf5** and **test_dc2_validation_9816.hdf5**) and the configuration file available in `examples/configs/FZBoost.yaml` to generate a small sample of photo-z PDFs using the **FZBoost** algorithm available on RAIL's _estimation_ module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"fzboost\"></a>\n",
    "### Photo-z Results\n",
    "#### Run FZBoost\n",
    "\n",
    "Go to dir  `<your_path>/RAIL/examples/estimation/` and run the command:\n",
    "\n",
    "`python main.py configs/FZBoost.yaml`\n",
    "\n",
    "The photo-z output files (inputs for this notebook) will be writen at: \n",
    "\n",
    "`<your_path>/RAIL/examples/estimation/results/FZBoost/test_FZBoost.hdf5`. \n",
    "\n",
    "Let's use the ancillary function **read_pz_output** to facilitate the reading of all necessary data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_path = '/Users/sam/WORK/software/TMPRAIL/RAIL' # replace this with your local path to RAIL's parent dir\n",
    "pdfs_file =  os.path.join(my_path, \"examples/estimation/results/FZBoost/test_FZBoost.hdf5\")\n",
    "ztrue_file =  os.path.join(my_path, \"tests/data/test_dc2_validation_9816.hdf5\")\n",
    "pdfs, zgrid, ztrue, photoz_mode = read_pz_output(pdfs_file, ztrue_file) # all numpy arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inputs for the metrics shown above are the array of true (or spectroscopic) redshifts, and an ensemble of photo-z PDFs (a `qp.Ensemble` object). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fzdata = qp.Ensemble(qp.interp, data=dict(xvals=zgrid, yvals=pdfs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** \n",
    "<a class=\"anchor\" id=\"metrics\"></a>\n",
    "# Metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"pit\"></a>\n",
    "## PIT\n",
    "\n",
    "The Probability Integral Transform (PIT), is the Cumulative Distribution Function (CDF) of the photo-z PDF \n",
    "\n",
    "$$ \\mathrm{CDF}(f, q)\\ =\\ \\int_{-\\infty}^{q}\\ f(z)\\ dz $$\n",
    "\n",
    "evaluated at the galaxy's true redshift for every galaxy $i$ in the catalog.\n",
    "\n",
    "$$ \\mathrm{PIT}(p_{i}(z);\\ z_{i})\\ =\\ \\int_{-\\infty}^{z^{true}_{i}}\\ p_{i}(z)\\ dz $$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitobj = PIT(fzdata, ztrue)\n",
    "quant_ens, metamets = pitobj.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The _evaluate_ method PIT class returns two objects, a quantile distribution based on the full set of PIT values (a frozen distribution object), and a dictionary of meta metrics associated to PIT (to be detailed below). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_ens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metamets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PIT values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pit_vals = np.array(pitobj._pit_samps)\n",
    "pit_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PIT outlier rate\n",
    "\n",
    "The PIT outlier rate is a global metric defined as the fraction of galaxies in the sample with extreme PIT values. The lower and upper limits for considering a PIT as outlier are optional parameters set at the Metrics instantiation (default values are: PIT $<10^{-4}$ or PIT $>0.9999$). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pit_out_rate = PITOutRate(pit_vals, quant_ens).evaluate()\n",
    "print(f\"PIT outlier rate of this sample: {pit_out_rate:.6f}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"qq\"></a>\n",
    "## PIT-QQ plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histogram of PIT values is a useful tool for a qualitative assessment of PDFs quality. It shows whether the PDFs are:\n",
    "* biased (tilted PIT histogram)\n",
    "* under-dispersed (excess counts close to the boudaries 0 and 1)\n",
    "* over-dispersed (lack of counts close the boudaries 0 and 1)\n",
    "* well-calibrated (flat histogram)\n",
    "\n",
    "Following the standards in DC1 paper, the PIT histogram is accompanied by the quantile-quantile (QQ), which can be used to compare qualitatively the PIT distribution obtained with the PDFs agaist the ideal case (uniform distribution). The closer the QQ plot is to the diagonal, the better is the PDFs calibration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pit_qq(pdfs, zgrid, ztrue, title=\"PIT-QQ - toy data\", code=\"FZBoost\",\n",
    "                pit_out_rate=pit_out_rate, savefig=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The black horizontal line represents the ideal case where the PIT histogram would behave as a uniform distribution U(0,1). \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"summary_stats\"></a>\n",
    "# Summary statistics of CDF-based metrics\n",
    "\n",
    "To evaluate globally the quality of PDFs estimates, `rail.evaluation` provides a set of metrics to compare the empirical distributions of PIT values with the reference uniform distribution, U(0,1). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"ks\"></a>\n",
    "### Kolmogorov-Smirnov  \n",
    "\n",
    "Let's start with the traditional Kolmogorov-Smirnov (KS) statistic test, which is the maximum difference between the empirical and the expected cumulative distributions of PIT values:\n",
    "\n",
    "$$\n",
    "\\mathrm{KS} \\equiv \\max_{PIT} \\Big( \\left| \\ \\mathrm{CDF} \\small[ \\hat{f}, z \\small] - \\mathrm{CDF} \\small[ \\tilde{f}, z \\small] \\  \\right| \\Big)\n",
    "$$\n",
    "\n",
    "Where $\\hat{f}$ is the PIT distribution and $\\tilde{f}$ is U(0,1). Therefore, the smaller value of KS the closer the PIT distribution is to be uniform. The `evaluate` method of the PITKS class returns a named tuple with the statistic and p-value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ksobj = PITKS(pit_vals, quant_ens)\n",
    "ks_stat_and_pval = ksobj.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_stat_and_pval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visual interpretation of the KS statistic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_plot(pitobj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"KS metric of this sample: {ks_stat_and_pval.statistic:.4f}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"cvm\"></a>\n",
    "### Cramer-von Mises\n",
    "\n",
    "Similarly, let's calculate the Cramer-von Mises (CvM) test, a variant of the KS statistic defined as the mean-square difference between the CDFs of an empirical PDF and the true PDFs:\n",
    "\n",
    "$$ \\mathrm{CvM}^2 \\equiv \\int_{-\\infty}^{\\infty} \\Big( \\mathrm{CDF} \\small[ \\hat{f}, z \\small] \\ - \\ \\mathrm{CDF} \\small[ \\tilde{f}, z \\small] \\Big)^{2} \\mathrm{dCDF}(\\tilde{f}, z) $$ \n",
    "\n",
    "\n",
    "on the distribution of PIT values, which should be uniform if the PDFs are perfect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvmobj = PITCvM(pit_vals, quant_ens)\n",
    "cvm_stat_and_pval = cvmobj.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"CvM metric of this sample: {cvm_stat_and_pval.statistic:.4f}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"ad\"></a>\n",
    "### Anderson-Darling \n",
    "\n",
    "Another variation of the KS statistic is the Anderson-Darling (AD) test, a weighted mean-squared difference featuring enhanced sensitivity to discrepancies in the tails of the distribution. \n",
    "\n",
    "$$ \\mathrm{AD}^2 \\equiv N_{tot} \\int_{-\\infty}^{\\infty} \\frac{\\big( \\mathrm{CDF} \\small[ \\hat{f}, z \\small] \\ - \\ \\mathrm{CDF} \\small[ \\tilde{f}, z \\small] \\big)^{2}}{\\mathrm{CDF} \\small[ \\tilde{f}, z \\small] \\big( 1 \\ - \\ \\mathrm{CDF} \\small[ \\tilde{f}, z \\small] \\big)}\\mathrm{dCDF}(\\tilde{f}, z) $$ \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adobj = PITAD(pit_vals, quant_ens)\n",
    "ad_stat_crit_sig = adobj.evaluate()\n",
    "ad_stat_crit_sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_stat_crit_sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"AD metric of this sample: {ad_stat_crit_sig.statistic:.4f}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to remove catastrophic outliers before calculating the integral for the sake of preserving numerical instability. For instance, Schmidt et al. computed the Anderson-Darling statistic within the interval (0.01, 0.99)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_stat_crit_sig_cut = adobj.evaluate(pit_min=0.01, pit_max=0.99)\n",
    "print(f\"AD metric of this sample: {ad_stat_crit_sig.statistic:.4f}\") \n",
    "print(f\"AD metric for 0.01 < PIT < 0.99: {ad_stat_crit_sig_cut.statistic:.4f}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"cde_loss\"></a>\n",
    "# CDE Loss\n",
    "\n",
    "\n",
    "\n",
    "In the absence of true photo-z posteriors, the metric used to evaluate individual PDFs is the **Conditional Density Estimate (CDE) Loss**, a metric analogue to the root-mean-squared-error:\n",
    "\n",
    "$$ L(f, \\hat{f}) \\equiv  \\int \\int {\\big(f(z | x) - \\hat{f}(z | x) \\big)}^{2} dzdP(x), $$ \n",
    "\n",
    "where $f(z | x)$ is the true photo-z PDF and $\\hat{f}(z | x)$ is the estimated PDF in terms of the photometry $x$. Since $f(z | x)$  is unknown, we estimate the **CDE Loss** as described in [Izbicki & Lee, 2017 (arXiv:1704.08095)](https://arxiv.org/abs/1704.08095). :\n",
    "\n",
    "$$ \\mathrm{CDE} = \\mathbb{E}\\big(  \\int{{\\hat{f}(z | X)}^2 dz} \\big) - 2{\\mathbb{E}}_{X, Z}\\big(\\hat{f}(Z, X) \\big) + K_{f},  $$\n",
    "\n",
    "\n",
    "where the first term is the expectation value of photo-z posterior with respect to the marginal distribution of the covariates X, and the second term is the expectation value  with respect to the joint distribution of observables X and the space Z of all possible redshifts (in practice, the centroids of the PDF bins), and the third term is a constant depending on the true conditional densities $f(z | x)$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdelossobj = CDELoss(fzdata, zgrid, ztrue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cde_stat_and_pval = cdelossobj.evaluate()\n",
    "cde_stat_and_pval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"CDE loss of this sample: {cde_stat_and_pval.statistic:.2f}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"summary\"></a>\n",
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = Summary(pdfs, zgrid, ztrue)\n",
    "summary.markdown_metrics_table(pitobj=pitobj) # pitobj as optional input to speed-up metrics evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.markdown_metrics_table(pitobj=pitobj, show_dc1=\"FlexZBoost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
