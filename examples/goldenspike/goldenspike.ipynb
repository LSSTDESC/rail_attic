{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "449c685e",
   "metadata": {},
   "source": [
    "# Goldenspike, an example of an end-2-end analysis using RAIL\n",
    "\n",
    "This notebook demonstrates how to use a the various RAIL Modules to draw synthetic samples of fluxes by color, apply physical effects to them, train photo-Z estimators on the samples, test and validate the preformance of those estimators, and to use the RAIL summarization modules to obtain n(z) estimates based on the p(z) estimates.\n",
    "\n",
    "### Creation \n",
    "\n",
    "Note that in the parlance of the Creation Module, \"degradation\" is any post-processing that occurs to the \"true\" sample generated by the Creation Engine.  This can include adding photometric errors, applying quality cuts, introducing systematic biases, etc.\n",
    "\n",
    "In this notebook, we will draw both test and training samples from a RAIL Engine object. Then we will demonstrate how to use RAIL degraders to apply effects to those samples.\n",
    "\n",
    "### Training and Estimation\n",
    "\n",
    "The RAIL Trainer modules \"train\" or \"inform\" models used to estimate p(z) given band fluxes (and potentially other information).\n",
    "\n",
    "The RAIL Estimation modules then use those same models to actually apply the model and extract the p(z) estimates.\n",
    "\n",
    "### p(z) Validation \n",
    "\n",
    "The RAIL Validator module applies various metrics "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c7d44f",
   "metadata": {},
   "source": [
    "###  Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295da0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prerquisites, os, and numpy\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5234e6a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac482bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Va\n",
    "import rail\n",
    "from rail.creation.degradation import LSSTErrorModel, InvRedshiftIncompleteness, LineConfusion, QuantityCut\n",
    "from rail.creation.engines.flowEngine import FlowEngine, FlowPosterior\n",
    "from rail.core.data import TableHandle\n",
    "from rail.core.stage import RailStage\n",
    "from rail.core.utilStages import ColumnMapper, TableConverter\n",
    "\n",
    "from rail.estimation.algos.bpz_lite import BPZ_lite\n",
    "from rail.estimation.algos.trainZ import Train_trainZ, TrainZ\n",
    "from rail.estimation.algos.sklearn_nn import Train_SimpleNN, SimpleNN\n",
    "from rail.estimation.algos.randomPZ import RandomPZ\n",
    "from rail.estimation.algos.flexzboost import Train_FZBoost, FZBoost\n",
    "\n",
    "from rail.evaluation.evaluator import Evaluator\n",
    "\n",
    "from rail.summarization.algos.naiveStack import NaiveStack\n",
    "from rail.summarization.algos.pointEstimateHist import PointEstimateHist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00fc25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DS = RailStage.data_store\n",
    "DS.__class__.allow_overwrite = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6758a26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAIL_DIR = os.path.join(os.path.dirname(rail.__file__), '..')\n",
    "flow_file = os.path.join(RAIL_DIR, 'examples/goldenspike/data/pretrained_flow.pkl')\n",
    "bands = ['u','g','r','i','z','y']\n",
    "band_dict = {band:f'mag_{band}_lsst' for band in bands}\n",
    "rename_dict = {f'mag_{band}_lsst_err':f'mag_err_{band}_lsst' for band in bands}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902d4a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_engine_test = FlowEngine.make_stage(name='flow_engine_test', \n",
    "                                         flow=flow_file, n_samples=50)\n",
    "      \n",
    "lsst_error_model_test = LSSTErrorModel.make_stage(name='lsst_error_model_test',\n",
    "                                                  bandNames=band_dict)\n",
    "                \n",
    "col_remapper_test = ColumnMapper.make_stage(name='col_remapper_test', hdf5_groupname='',\n",
    "                                            columns=rename_dict)\n",
    "\n",
    "flow_post_test = FlowPosterior.make_stage(name='flow_post_test',\n",
    "                                          column='redshift', flow=flow_file,\n",
    "                                          grid=np.linspace(0., 5., 21))\n",
    "\n",
    "table_conv_test = TableConverter.make_stage(name='table_conv_test', output_format='numpyDict', \n",
    "                                            seed=12345)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf1c36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_orig = flow_engine_test.sample(50, 12345)\n",
    "test_data_errs = lsst_error_model_test(test_data_orig)\n",
    "test_data_pq = col_remapper_test(test_data_errs)\n",
    "test_data_post = flow_post_test.get_posterior(test_data_pq, 'redshift', err_samples=None)\n",
    "test_data = table_conv_test(test_data_pq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655434f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_engine_train = FlowEngine.make_stage(name='flow_engine_train', \n",
    "                                          flow=flow_file, n_samples=50,\n",
    "                                          seed=12345)\n",
    "\n",
    "lsst_error_model_train = LSSTErrorModel.make_stage(name='lsst_error_model_train',\n",
    "                                                   bandNames=band_dict)\n",
    "\n",
    "inv_redshift = InvRedshiftIncompleteness.make_stage(name='inv_redshift',\n",
    "                                                    pivot_redshift=1.0)\n",
    "\n",
    "line_confusion = LineConfusion.make_stage(name='line_confusion', \n",
    "                                          true_wavelen=5007., wrong_wavelen=3727., frac_wrong=0.05)\n",
    "\n",
    "quantity_cut = QuantityCut.make_stage(name='quantity_cut',    \n",
    "                                      cuts={'mag_i_lsst': 25.3})\n",
    "\n",
    "col_remapper_train = ColumnMapper.make_stage(name='col_remapper_train', columns=rename_dict)\n",
    "   \n",
    "table_conv_train = TableConverter.make_stage(name='table_conv_train', output_format='numpyDict')\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6c5fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_orig = flow_engine_train.sample(50, 12345)\n",
    "train_data_errs = lsst_error_model_train(train_data_orig)\n",
    "train_data_inc = inv_redshift(train_data_errs)\n",
    "train_data_conf = line_confusion(train_data_inc)\n",
    "train_data_cut = quantity_cut(train_data_conf)\n",
    "train_data_pq = col_remapper_train(train_data_cut)\n",
    "train_data = table_conv_train(train_data_pq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48eed11",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trainZ = Train_trainZ.make_stage(name='train_trainZ', input='inprogress_output_table_conv_train.hdf5', \n",
    "                                       model='trainZ.pkl', hdf5_groupname='')\n",
    "\n",
    "train_simpleNN = Train_SimpleNN.make_stage(name='train_simpleNN', input='inprogress_output_table_conv_train.hdf5', \n",
    "                                           model='simpleNN.pkl', hdf5_groupname='')\n",
    "\n",
    "train_fzboost = Train_FZBoost.make_stage(name='train_FZBoost', input='inprogress_output_table_conv_train.pq', \n",
    "                                         model='fzboost.pkl', hdf5_groupname='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b544823",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trainZ.inform(train_data)\n",
    "#train_simpleNN.inform(train_data)\n",
    "#train_fzboost.inform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68120a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_bpz = BPZ_lite.make_stage(name='test_bpz', \n",
    "                               hdf5_groupname='', columns_file='../estimation/configs/test_bpz.columns')\n",
    "\n",
    "test_trainZ = TrainZ.make_stage(name='test_trainZ', hdf5_groupname='', model=train_trainZ.get_handle('model'))\n",
    "\n",
    "test_randomPZ = RandomPZ.make_stage(name='test_randomZ', hdf5_groupname='')\n",
    "\n",
    "#test_simpleNN = SimpleNN.make_stage(name='test_simpleNN', \n",
    "#                                    model_file='simpleNN.pkl')\n",
    "\n",
    "#test_fzboost = FZBoost.create(name='test_FZBoost', \n",
    "#                              model_file='fzboost.pkl', \n",
    "#                              aliases=dict(input='test_data', output='fzboost_estim'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9710ae8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trainZ.get_handle('model').path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f490f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bpz_estim = test_bpz.estimate(test_data)\n",
    "trainZ_estim = test_trainZ.estimate(test_data)\n",
    "randomPZ_estim = test_randomPZ.estimate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26ac2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dict = dict(bpz=bpz_estim, trainZ=trainZ_estim)\n",
    "truth = test_data_orig\n",
    "\n",
    "result_dict = {}\n",
    "for key, val in eval_dict.items():\n",
    "    the_eval = Evaluator.make_stage(name=f'{key}_eval', truth=truth)\n",
    "    result_dict[key] = the_eval.evaluate(val, truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320cc596",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tables_io\n",
    "results_tables = {key:tables_io.convertObj(val.data, tables_io.types.PD_DATAFRAME) for key,val in result_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9afca4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_tables['bpz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989d667a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_tables['trainZ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c45122",
   "metadata": {},
   "outputs": [],
   "source": [
    "point_estimate_test = PointEstimateHist.make_stage(name='point_estimate_test')\n",
    "naive_stack_test = NaiveStack.make_stage(name='naive_stack_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ae9a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "point_estimate_ens = point_estimate_test.summarize(eval_dict['bpz'])\n",
    "naive_stack_ens = naive_stack_test.summarize(eval_dict['bpz'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a164153e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = naive_stack_ens.data.plot_native(xlim=(0,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b049a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = point_estimate_ens.data.plot_native(xlim=(0,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb78a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ceci\n",
    "pipe = ceci.Pipeline.interactive()\n",
    "stages = [flow_engine_test, lsst_error_model_test, col_remapper_test, table_conv_test,\n",
    "          flow_engine_train, lsst_error_model_train, col_remapper_train, table_conv_train, \n",
    "          inv_redshift, line_confusion, quantity_cut,\n",
    "          train_trainZ, test_bpz, test_trainZ, test_randomPZ,\n",
    "          point_estimate_test, naive_stack_test]\n",
    "for stage in stages:\n",
    "    pipe.add_stage(stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194bc590",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.initialize(dict(flow=flow_file), dict(output_dir='.', log_dir='.', resume=False), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a842a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.save('goldenspike.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf12e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.test_trainZ.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2c6071",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = ceci.Pipeline.read('goldenspike.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728303e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc94d2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
