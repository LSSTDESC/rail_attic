{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo: RAIL Evaluation \n",
    "\n",
    "Author: Sam Schmidt, Alex Malz, Julia Gschwend, others...\n",
    "\n",
    "last run successfully: April 28, 2023 (with qp-prob >= 0.8.2)\n",
    "\n",
    "The purpose of this notebook is to demonstrate the application of the metrics scripts to be used on the photo-z PDF catalogs produced by the PZ working group. The first implementation of the _evaluation_ module is based on the refactoring of the code used in [Schmidt et al. 2020](https://arxiv.org/pdf/2001.03621.pdf), available on Github repository [PZDC1paper](https://github.com/LSSTDESC/PZDC1paper). \n",
    "\n",
    "To run this notebook, you must install qp and have the notebook in the same directory as `utils.py` (available in RAIL's examples directrory). You must also have installed all RAIL dependencies, particularly for the estimation codes that you want to run, as well as ceci, qp, tables_io, etc...  See the RAIL installation instructions for more info.\n",
    "\n",
    "### Contents\n",
    "\n",
    "* [Data](#data)\n",
    " - [Photo-z Results](#fzboost)\n",
    "* [CDF-based metrics](#metrics)\n",
    " - [PIT](#pit) \n",
    " - [QQ plot](#qq) \n",
    "* [Summary statistics of CDF-based metrics](#summary_stats)\n",
    "  - [KS](#ks) \n",
    "  - [CvM](#cvm) \n",
    "  - [AD](#ad) \n",
    "  - [KLD](#kld) \n",
    "* [CDE loss](#cde_loss)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rail\n",
    "from rail.evaluation.metrics.pit import *\n",
    "from rail.evaluation.metrics.cdeloss import *\n",
    "from rail.evaluation.evaluator import Evaluator\n",
    "from rail.core.data import QPHandle, TableHandle\n",
    "from rail.core.stage import RailStage\n",
    "from utils import plot_pit_qq, ks_plot\n",
    "import qp \n",
    "import os\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set up the data store, for more information on the data store, see the golden spike example notebook in RAIL/examples/goldenspike/goldenspike.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS = RailStage.data_store\n",
    "DS.__class__.allow_overwrite = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"data\"></a>\n",
    "# Data  \n",
    "\n",
    "\n",
    "To compute the photo-z metrics of a given test sample, it is necessary to read the output of a photo-z code containing galaxies' photo-z PDFs. Let's use the toy data available in `tests/data/` (**test_dc2_training_9816.hdf5** and **test_dc2_validation_9816.hdf5**) to generate a small sample of photo-z PDFs using the **FZBoost** algorithm available on RAIL's _estimation_ module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"fzboost\"></a>\n",
    "### Photo-z Results\n",
    "#### Run FZBoost\n",
    "\n",
    "If you have run the notebook `RAIL_estimation_demo.ipynb`, this will produce a file `output_fzboost.fits`, \n",
    "writen at the location:<br> \n",
    "`<your_path>/RAIL/examples/estimation_examples/output_fzboost.fits`. \n",
    "\n",
    "Otherwise we can download the file from NERSC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to set up some  paths for the Data Store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rail.core.utils import RAILDIR\n",
    "pdfs_file = os.path.join(RAILDIR, 'rail/examples_data/evaluation_data/data/output_fzboost.hdf5')\n",
    "ztrue_file = os.path.join(RAILDIR, 'rail/examples_data/testdata/test_dc2_validation_9816.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(pdfs_file):\n",
    "    try:\n",
    "        os.makedirs(os.path.dirname(pdfs_file))\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    curl_com = f\"curl -o {pdfs_file} https://portal.nersc.gov/cfs/lsst/schmidt9/output_fzboost.hdf5\"\n",
    "    os.system(curl_com)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the data in, note that the fzdata is a `qp` Ensemble, and thus we should read it in as a `QPHandle` type file, while the ztrue_data is tabular data, and should be read in as a `Tablehandle` when adding to the data store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fzdata = DS.read_file('pdfs_data', QPHandle, pdfs_file)\n",
    "ztrue_data = DS.read_file('ztrue_data', TableHandle, ztrue_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ztrue = ztrue_data()['photometry']['redshift']\n",
    "zgrid = fzdata().metadata()['xvals'].ravel()\n",
    "photoz_mode = fzdata().mode(grid=zgrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth = DS.add_data('truth', ztrue_data()['photometry'], TableHandle)\n",
    "ensemble = DS.add_data('ensemble', fzdata, QPHandle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make an evaulator stage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's set up the Evaluator stage to compute our metrics for the FZBoost data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FZB_eval = Evaluator.make_stage(name='FZB_eval', truth=truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FZB_results = FZB_eval.evaluate(ensemble(), truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can view the results as a pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tables_io\n",
    "results_df= tables_io.convertObj(FZB_results(), tables_io.types.PD_DATAFRAME)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, there we have it, a way to generate all of our summary statistics for FZBoost. And note also that the results file has been written out to `output_FZB_eval.hdf5`, the name we specified when we ran `make_stage` (with output_ prepended).<br>\n",
    "\n",
    "As an alternative, and to allow for a little more explanation for each individual metric, we can calculate the metrics using functions from the evaluation class separate from the stage infrastructure.  Here are some examples below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** \n",
    "<a class=\"anchor\" id=\"metrics\"></a>\n",
    "# Metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"pit\"></a>\n",
    "## PIT\n",
    "\n",
    "The Probability Integral Transform (PIT), is the Cumulative Distribution Function (CDF) of the photo-z PDF \n",
    "\n",
    "$$ \\mathrm{CDF}(f, q)\\ =\\ \\int_{-\\infty}^{q}\\ f(z)\\ dz $$\n",
    "\n",
    "evaluated at the galaxy's true redshift for every galaxy $i$ in the catalog.\n",
    "\n",
    "$$ \\mathrm{PIT}(p_{i}(z);\\ z_{i})\\ =\\ \\int_{-\\infty}^{z^{true}_{i}}\\ p_{i}(z)\\ dz $$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qp.metrics.pit import PIT\n",
    "pitobj = PIT(fzdata(), ztrue)\n",
    "quant_ens = pitobj.pit\n",
    "metamets = pitobj.calculate_pit_meta_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The _evaluate_ method PIT class returns two objects, a quantile distribution based on the full set of PIT values (a frozen distribution object), and a dictionary of meta metrics associated to PIT (to be detailed below). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_ens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metamets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PIT values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pit_vals = np.array(pitobj.pit_samps)\n",
    "pit_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PIT outlier rate\n",
    "\n",
    "The PIT outlier rate is a global metric defined as the fraction of galaxies in the sample with extreme PIT values. The lower and upper limits for considering a PIT as outlier are optional parameters set at the Metrics instantiation (default values are: PIT $<10^{-4}$ or PIT $>0.9999$). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pit_out_rate = metamets['outlier_rate']\n",
    "print(f\"PIT outlier rate of this sample: {pit_out_rate:.6f}\") \n",
    "pit_out_rate = pitobj.evaluate_PIT_outlier_rate()\n",
    "print(f\"PIT outlier rate of this sample: {pit_out_rate:.6f}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"qq\"></a>\n",
    "## PIT-QQ plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histogram of PIT values is a useful tool for a qualitative assessment of PDFs quality. It shows whether the PDFs are:\n",
    "* biased (tilted PIT histogram)\n",
    "* under-dispersed (excess counts close to the boudaries 0 and 1)\n",
    "* over-dispersed (lack of counts close the boudaries 0 and 1)\n",
    "* well-calibrated (flat histogram)\n",
    "\n",
    "Following the standards in DC1 paper, the PIT histogram is accompanied by the quantile-quantile (QQ), which can be used to compare qualitatively the PIT distribution obtained with the PDFs agaist the ideal case (uniform distribution). The closer the QQ plot is to the diagonal, the better is the PDFs calibration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfs = fzdata.data.objdata()['yvals']\n",
    "plot_pit_qq(pdfs, zgrid, ztrue, title=\"PIT-QQ - toy data\", code=\"FZBoost\",\n",
    "                pit_out_rate=pit_out_rate, savefig=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The black horizontal line represents the ideal case where the PIT histogram would behave as a uniform distribution U(0,1). \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"summary_stats\"></a>\n",
    "# Summary statistics of CDF-based metrics\n",
    "\n",
    "To evaluate globally the quality of PDFs estimates, `rail.evaluation` provides a set of metrics to compare the empirical distributions of PIT values with the reference uniform distribution, U(0,1). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"ks\"></a>\n",
    "### Kolmogorov-Smirnov  \n",
    "\n",
    "Let's start with the traditional Kolmogorov-Smirnov (KS) statistic test, which is the maximum difference between the empirical and the expected cumulative distributions of PIT values:\n",
    "\n",
    "$$\n",
    "\\mathrm{KS} \\equiv \\max_{PIT} \\Big( \\left| \\ \\mathrm{CDF} \\small[ \\hat{f}, z \\small] - \\mathrm{CDF} \\small[ \\tilde{f}, z \\small] \\  \\right| \\Big)\n",
    "$$\n",
    "\n",
    "Where $\\hat{f}$ is the PIT distribution and $\\tilde{f}$ is U(0,1). Therefore, the smaller value of KS the closer the PIT distribution is to be uniform. The `evaluate` method of the PITKS class returns a named tuple with the statistic and p-value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_stat_and_pval = metamets['ks']\n",
    "print(f\"PIT KS stat and pval: {ks_stat_and_pval}\") \n",
    "ks_stat_and_pval = pitobj.evaluate_PIT_KS()\n",
    "print(f\"PIT KS stat and pval: {ks_stat_and_pval}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visual interpretation of the KS statistic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_plot(pitobj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"KS metric of this sample: {ks_stat_and_pval.statistic:.4f}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"cvm\"></a>\n",
    "### Cramer-von Mises\n",
    "\n",
    "Similarly, let's calculate the Cramer-von Mises (CvM) test, a variant of the KS statistic defined as the mean-square difference between the CDFs of an empirical PDF and the true PDFs:\n",
    "\n",
    "$$ \\mathrm{CvM}^2 \\equiv \\int_{-\\infty}^{\\infty} \\Big( \\mathrm{CDF} \\small[ \\hat{f}, z \\small] \\ - \\ \\mathrm{CDF} \\small[ \\tilde{f}, z \\small] \\Big)^{2} \\mathrm{dCDF}(\\tilde{f}, z) $$ \n",
    "\n",
    "\n",
    "on the distribution of PIT values, which should be uniform if the PDFs are perfect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvm_stat_and_pval = metamets['cvm']\n",
    "print(f\"PIT CvM stat and pval: {cvm_stat_and_pval}\") \n",
    "cvm_stat_and_pval = pitobj.evaluate_PIT_CvM()\n",
    "print(f\"PIT CvM stat and pval: {cvm_stat_and_pval}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"CvM metric of this sample: {cvm_stat_and_pval.statistic:.4f}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"ad\"></a>\n",
    "### Anderson-Darling \n",
    "\n",
    "Another variation of the KS statistic is the Anderson-Darling (AD) test, a weighted mean-squared difference featuring enhanced sensitivity to discrepancies in the tails of the distribution. \n",
    "\n",
    "$$ \\mathrm{AD}^2 \\equiv N_{tot} \\int_{-\\infty}^{\\infty} \\frac{\\big( \\mathrm{CDF} \\small[ \\hat{f}, z \\small] \\ - \\ \\mathrm{CDF} \\small[ \\tilde{f}, z \\small] \\big)^{2}}{\\mathrm{CDF} \\small[ \\tilde{f}, z \\small] \\big( 1 \\ - \\ \\mathrm{CDF} \\small[ \\tilde{f}, z \\small] \\big)}\\mathrm{dCDF}(\\tilde{f}, z) $$ \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_stat_crit_sig = metamets['ad']\n",
    "print(f\"PIT AD stat and pval: {ad_stat_crit_sig}\") \n",
    "ad_stat_crit_sig = pitobj.evaluate_PIT_anderson_ksamp()\n",
    "print(f\"PIT AD stat and pval: {ad_stat_crit_sig}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"AD metric of this sample: {ad_stat_crit_sig.statistic:.4f}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to remove catastrophic outliers before calculating the integral for the sake of preserving numerical instability. For instance, Schmidt et al. computed the Anderson-Darling statistic within the interval (0.01, 0.99)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_stat_crit_sig_cut = pitobj.evaluate_PIT_anderson_ksamp(pit_min=0.01, pit_max=0.99)\n",
    "print(f\"AD metric of this sample: {ad_stat_crit_sig.statistic:.4f}\") \n",
    "print(f\"AD metric for 0.01 < PIT < 0.99: {ad_stat_crit_sig_cut.statistic:.4f}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"cde_loss\"></a>\n",
    "# CDE Loss\n",
    "\n",
    "\n",
    "\n",
    "In the absence of true photo-z posteriors, the metric used to evaluate individual PDFs is the **Conditional Density Estimate (CDE) Loss**, a metric analogue to the root-mean-squared-error:\n",
    "\n",
    "$$ L(f, \\hat{f}) \\equiv  \\int \\int {\\big(f(z | x) - \\hat{f}(z | x) \\big)}^{2} dzdP(x), $$ \n",
    "\n",
    "where $f(z | x)$ is the true photo-z PDF and $\\hat{f}(z | x)$ is the estimated PDF in terms of the photometry $x$. Since $f(z | x)$  is unknown, we estimate the **CDE Loss** as described in [Izbicki & Lee, 2017 (arXiv:1704.08095)](https://arxiv.org/abs/1704.08095). :\n",
    "\n",
    "$$ \\mathrm{CDE} = \\mathbb{E}\\big(  \\int{{\\hat{f}(z | X)}^2 dz} \\big) - 2{\\mathbb{E}}_{X, Z}\\big(\\hat{f}(Z, X) \\big) + K_{f},  $$\n",
    "\n",
    "\n",
    "where the first term is the expectation value of photo-z posterior with respect to the marginal distribution of the covariates X, and the second term is the expectation value  with respect to the joint distribution of observables X and the space Z of all possible redshifts (in practice, the centroids of the PDF bins), and the third term is a constant depending on the true conditional densities $f(z | x)$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdelossobj = CDELoss(fzdata.data, zgrid, ztrue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cde_stat_and_pval = cdelossobj.evaluate()\n",
    "cde_stat_and_pval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"CDE loss of this sample: {cde_stat_and_pval.statistic:.2f}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that all of the quantities as run individually are identical to the quantities in our summary table, a nice check that things have run properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
